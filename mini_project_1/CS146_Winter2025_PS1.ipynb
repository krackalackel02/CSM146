{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "40nOq82Ha1zB"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asomlC24dVik"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27591,
     "status": "ok",
     "timestamp": 1737409271645,
     "user": {
      "displayName": "ANDREY STOROZHENKO",
      "userId": "09216071367880900372"
     },
     "user_tz": 480
    },
    "id": "e_NuDNh9rUos",
    "outputId": "a94f5bb0-0227-48ba-e0ab-2ea87ebf0f21"
   },
   "outputs": [],
   "source": [
    "# To add your own Drive Run this cell.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "RWPBfJLfrkhJ"
   },
   "outputs": [],
   "source": [
    "# Please append your own directory after â€˜/content/drive/My Drive/'\n",
    "# where you have nutil.py and adult_subsample.csv\n",
    "### ========== TODO : START ========== ###\n",
    "# sys.path += ['/content/drive/My Drive/cm146/pset1']\n",
    "# sys.path += ['/content/drive/']\n",
    "\n",
    "### ========== TODO : END ========== ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "yxKg7xF1r82H"
   },
   "outputs": [],
   "source": [
    "from nutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "55EocyDPsWIb"
   },
   "outputs": [],
   "source": [
    "# Use only the provided packages!\n",
    "import math\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sclZvDOTPS7"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "dxpkWVRetDgo"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Immutatble classes\n",
    "######################################################################\n",
    "\n",
    "class Classifier(object) :\n",
    "    \"\"\"\n",
    "    Classifier interface.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(Classifier) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        \"\"\"\n",
    "        A classifier that always predicts the majority class.\n",
    "\n",
    "        Attributes\n",
    "        --------------------\n",
    "            prediction_ -- majority class\n",
    "        \"\"\"\n",
    "        self.prediction_ = None\n",
    "\n",
    "    def fit(self, X, y) :\n",
    "        \"\"\"\n",
    "        Build a majority vote classifier from the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "            y    -- numpy array of shape (n,), target classes\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            self -- an instance of self\n",
    "        \"\"\"\n",
    "        majority_val = Counter(y).most_common(1)[0][0]\n",
    "        self.prediction_ = majority_val\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) :\n",
    "        \"\"\"\n",
    "        Predict class values.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            y    -- numpy array of shape (n,), predicted classes\n",
    "        \"\"\"\n",
    "        if self.prediction_ is None :\n",
    "            raise Exception(\"Classifier not initialized. Perform a fit first.\")\n",
    "\n",
    "        n,d = X.shape\n",
    "        y = [self.prediction_] * n\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "yefbwe8EvH-V"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Mutatble classes\n",
    "######################################################################\n",
    "\n",
    "class RandomClassifier(Classifier) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        \"\"\"\n",
    "        A classifier that predicts according to the distribution of the classes.\n",
    "\n",
    "        Attributes\n",
    "        --------------------\n",
    "            probabilities_ -- class distribution dict (key = class, val = probability of class)\n",
    "        \"\"\"\n",
    "        self.probabilities_ = dict()\n",
    "\n",
    "    def fit(self, X, y) :\n",
    "        \"\"\"\n",
    "        Build a random classifier from the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "            y    -- numpy array of shape (n,), target classes\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            self -- an instance of self\n",
    "        \"\"\"\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part b: set self.probabilities_ according to the training set\n",
    "        count_0 = Counter(y)[0]\n",
    "        count_1 = Counter(y)[1]\n",
    "        total = count_0 + count_1\n",
    "\n",
    "        self.probabilities_[0] = count_0 / total\n",
    "        self.probabilities_[1] = count_1 / total\n",
    "\n",
    "        return self\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, seed=1234) :\n",
    "        \"\"\"\n",
    "        Predict class values.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "            seed -- integer, random seed\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            y    -- numpy array of shape (n,), predicted classes\n",
    "        \"\"\"\n",
    "        if self.probabilities_ is None :\n",
    "            raise Exception(\"Classifier not initialized. Perform a fit first.\")\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part b: predict the class for each test example\n",
    "        # hint: use np.random.choice (be careful of the parameters)\n",
    "        np.random.seed(seed)\n",
    "        classes = list(self.probabilities_.keys())\n",
    "        probabilities = list(self.probabilities_.values())\n",
    "        \n",
    "        n, d = X.shape\n",
    "        y = np.random.choice(classes, size=n, p=probabilities)\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b67EbazvTdmk"
   },
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "7m9qVosFwbAK"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Immutatble functions\n",
    "######################################################################\n",
    "\n",
    "def plot_histograms(X, y, Xnames, yname) :\n",
    "    n,d = X.shape  # n = number of examples, d =  number of features\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    ncol = 3\n",
    "    nrow = d // ncol + 1\n",
    "    for i in range(d) :\n",
    "        fig.add_subplot (nrow,ncol,i+1)\n",
    "        data, bins, align, labels = plot_histogram(X[:,i], y, Xname=Xnames[i], yname=yname, show = False)\n",
    "        n, bins, patches = plt.hist(data, bins=bins, align=align, alpha=0.5, label=labels)\n",
    "        plt.xlabel(Xnames[i])\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend() #plt.legend(loc='upper left')\n",
    "\n",
    "    plt.savefig ('histograms.pdf')\n",
    "\n",
    "\n",
    "def plot_histogram(X, y, Xname, yname, show = True) :\n",
    "    \"\"\"\n",
    "    Plots histogram of values in X grouped by y.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        X     -- numpy array of shape (n,d), feature values\n",
    "        y     -- numpy array of shape (n,), target classes\n",
    "        Xname -- string, name of feature\n",
    "        yname -- string, name of target\n",
    "    \"\"\"\n",
    "\n",
    "    # set up data for plotting\n",
    "    targets = sorted(set(y))\n",
    "    data = []; labels = []\n",
    "    for target in targets :\n",
    "        features = [X[i] for i in range(len(y)) if y[i] == target]\n",
    "        data.append(features)\n",
    "        labels.append('%s = %s' % (yname, target))\n",
    "\n",
    "    # set up histogram bins\n",
    "    features = set(X)\n",
    "    nfeatures = len(features)\n",
    "    test_range = list(range(int(math.floor(min(features))), int(math.ceil(max(features)))+1))\n",
    "    if nfeatures < 10 and sorted(features) == test_range:\n",
    "        bins = test_range + [test_range[-1] + 1] # add last bin\n",
    "        align = 'left'\n",
    "    else :\n",
    "        bins = 10\n",
    "        align = 'mid'\n",
    "\n",
    "    # plot\n",
    "    if show == True:\n",
    "        plt.figure()\n",
    "        n, bins, patches = plt.hist(data, bins=bins, align=align, alpha=0.5, label=labels)\n",
    "        plt.xlabel(Xname)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend() #plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    return data, bins, align, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "1Z8oJrMgxc4_"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Mutatble functions\n",
    "######################################################################\n",
    "\n",
    "def error(clf, X, y, ntrials=100, test_size=0.2) :\n",
    "    \"\"\"\n",
    "    Computes the classifier error over a random split of the data,\n",
    "    averaged over ntrials runs.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf         -- classifier\n",
    "        X           -- numpy array of shape (n,d), features values\n",
    "        y           -- numpy array of shape (n,), target classes\n",
    "        ntrials     -- integer, number of trials\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        train_error -- float, training error\n",
    "        test_error  -- float, test error\n",
    "        f1_score    -- float, test \"micro\" averaged f1 score\n",
    "    \"\"\"\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # compute cross-validation error using StratifiedShuffleSplit over ntrials\n",
    "\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    import numpy as np\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=ntrials, test_size=test_size, random_state=0)\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "\n",
    "        train_errors.append(1 - accuracy_score(y_train, y_train_pred))\n",
    "        test_errors.append(1 - accuracy_score(y_test, y_test_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_test_pred, average='micro'))\n",
    "\n",
    "    train_error = np.mean(train_errors)\n",
    "    test_error = np.mean(test_errors)\n",
    "    f1_score = np.mean(f1_scores)\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "    return train_error, test_error, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "kRkKf8DUxMdX"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Immutatble functions\n",
    "######################################################################\n",
    "\n",
    "\n",
    "def write_predictions(y_pred, filename, yname=None) :\n",
    "    \"\"\"Write out predictions to csv file.\"\"\"\n",
    "    out = open(filename, 'wb')\n",
    "    f = csv.writer(out)\n",
    "    if yname :\n",
    "        f.writerow([yname])\n",
    "    f.writerows(list(zip(y_pred)))\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnd5bCiPTxTj"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HdZPr0TsvYV"
   },
   "outputs": [],
   "source": [
    "\n",
    "######################################################################\n",
    "# main\n",
    "######################################################################\n",
    "\n",
    "def run_experiment(apply_scaling=False) :\n",
    "    # load adult_subsample dataset with correct file path\n",
    "    ### ========== TODO : START ========== ###\n",
    "    data_file =  \"./adult_subsample.csv\"\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "    data = load_data(data_file, header=1, predict_col=-1)\n",
    "\n",
    "    X = data.X; Xnames = data.Xnames\n",
    "    y = data.y; yname = data.yname\n",
    "    n,d = X.shape  # n = number of examples, d =  number of features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #========================================\n",
    "    # part a: plot histograms of each feature\n",
    "    print('Plotting...')\n",
    "    plot_histograms (X, y, Xnames=Xnames, yname=yname)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part i: Preprocess X (e.g., normalize)\n",
    "    # (try this after finishing the sections below)\n",
    "\n",
    "    # X = ?\n",
    "    scaler = StandardScaler()\n",
    "    if apply_scaling:\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #========================================\n",
    "    # train Majority Vote classifier on data\n",
    "    print('Classifying using Majority Vote...')\n",
    "    clf = MajorityVoteClassifier() # create MajorityVote classifier, which includes all model parameters\n",
    "    clf.fit(X, y)                  # fit training data using the classifier\n",
    "    y_pred = clf.predict(X)        # take the classifier and run it on the training data\n",
    "    train_error = 1 - metrics.accuracy_score(y, y_pred, normalize=True)\n",
    "    print('\\t-- training error: %.3f' % train_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part b: evaluate training error of Random classifier\n",
    "    print('Classifying using Random...')\n",
    "    clf = RandomClassifier ()\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    train_error = 1 - metrics.accuracy_score(y, y_pred)\n",
    "\n",
    "    print('\\t-- training error: %.3f' % train_error)\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part c: evaluate training error of Decision Tree classifier\n",
    "    print('Classifying using Decision Tree...')\n",
    "    clf = DecisionTreeClassifier(criterion='entropy')\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    train_error = 1 - metrics.accuracy_score(y, y_pred)\n",
    "\n",
    "    print('\\t-- training error: %.3f' % train_error)\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part d: evaluate training error of k-Nearest Neighbors classifier\n",
    "    # use k = 3, 5, 7 for n_neighbors\n",
    "    print('Classifying using k-Nearest Neighbors...')\n",
    "\n",
    "\n",
    "    # print the error for each k\n",
    "    for k in [3, 5, 7]:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)   \n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict(X)\n",
    "        train_error = 1 - metrics.accuracy_score(y, y_pred,normalize=True)\n",
    "        print(f'\\t-- training error for k={k}: {train_error:.3f}')\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part e: use cross-validation to compute average training and test error of classifiers\n",
    "    print('Investigating various classifiers...')\n",
    "    models = {\n",
    "        'MajorityVote': MajorityVoteClassifier(),\n",
    "        'Random': RandomClassifier(),\n",
    "        'DecisionTree': DecisionTreeClassifier(criterion='entropy'),\n",
    "        'KNN (k=5)': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        train_err, test_err, f1 = error(model, X, y,ntrials=20)\n",
    "        print(f'{model_name} -- Train Error: {train_err:.3f}, Test Error: {test_err:.3f}, F1 Score: {f1:.3f}')\n",
    "\n",
    "    # clf =\n",
    "\n",
    "    # summary = error(clf, X, y, ntrials=20)\n",
    "    # print(summary)\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part f: use 10-fold cross-validation to find the best value of k for k-Nearest Neighbors classifier\n",
    "    print('Finding the best k...')\n",
    "    k_values = range(1, 51, 2)\n",
    "    validation_errors = []\n",
    "\n",
    "    for k in k_values:\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(clf, X, y, cv=10)\n",
    "        validation_errors.append(1 - np.mean(scores))\n",
    "\n",
    "    plt.plot(k_values, validation_errors)\n",
    "    plt.xlabel('Number of Neighbors (k)')\n",
    "    plt.ylabel('Validation Error')\n",
    "    plt.title('KNN: Validation Error vs Number of Neighbors')\n",
    "    plt.show()\n",
    "\n",
    "    best_k = k_values[np.argmin(validation_errors)]\n",
    "    print(f'Best value of k: {best_k}, error: {np.min(validation_errors)}')\n",
    "\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part g: investigate decision tree classifier with various depths\n",
    "    print('Investigating depths...')\n",
    "    depths = range(1, 21)\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "\n",
    "    for depth in depths:\n",
    "        clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth)\n",
    "        train_err, test_err, _ = error(clf, X, y)\n",
    "        train_errors.append(train_err)\n",
    "        test_errors.append(test_err)\n",
    "\n",
    "    best_d = depths[np.argmin(test_errors)]\n",
    "    print(f'Best value of depth: {best_d}, test error: {np.min(test_errors)}')\n",
    "    plt.plot(depths, train_errors, label='Training Error')\n",
    "    plt.plot(depths, test_errors, label='Test Error')\n",
    "    plt.xlabel('Tree Depth')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Decision Tree: Error vs Tree Depth')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   ### ========== TODO : START ========== ###\n",
    "    # part h: investigate decision tree and k-Nearest Neighbors classifier with various training set sizes\n",
    "    print('Investigating training set sizes...')\n",
    "\n",
    "    # Initialize lists to store errors\n",
    "    d_tree_test = []\n",
    "    d_tree_train = []\n",
    "    knn_test = []\n",
    "    knn_train = []\n",
    "\n",
    "    # Stratified split to maintain class balance\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        x_train_data = X[train_index]\n",
    "        x_test_data = X[test_index]\n",
    "        y_train_data = y[train_index]\n",
    "        y_test_data = y[test_index]\n",
    "\n",
    "    # Initialize models with best hyperparameters\n",
    "    d_tree = DecisionTreeClassifier(criterion='entropy', max_depth=5)  # Replace 5 with the best depth if different\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)  # Replace 15 with the best k if different\n",
    "\n",
    "    # Fit models on the full training set initially\n",
    "    d_tree.fit(x_train_data, y_train_data)\n",
    "    knn.fit(x_train_data, y_train_data)\n",
    "\n",
    "    # Define the fractions of training data to evaluate\n",
    "    percentages = [x / 10.0 for x in range(1, 10)]\n",
    "\n",
    "    # Evaluate model performance for different training set sizes\n",
    "    for fraction in percentages:\n",
    "        # Compute errors for Decision Tree\n",
    "        d_train_error, d_test_error, _ = error(d_tree, X, y, ntrials=100, test_size=fraction)\n",
    "        d_tree_train.append(d_train_error)\n",
    "        d_tree_test.append(d_test_error)\n",
    "\n",
    "        # Compute errors for K-Nearest Neighbors\n",
    "        k_train_error, k_test_error, _ = error(knn, X, y, ntrials=100, test_size=fraction)\n",
    "        knn_train.append(k_train_error)\n",
    "        knn_test.append(k_test_error)\n",
    "\n",
    "    # Plotting results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    d_train_out, = plt.plot(percentages, d_tree_train, label='Decision Tree Training Error (max_depth=5)')\n",
    "    d_test_out, = plt.plot(percentages, d_tree_test, label='Decision Tree Test Error (max_depth=5)')\n",
    "    k_train_out, = plt.plot(percentages, knn_train, label=f'KNN Training Error (k={best_k})')\n",
    "    k_test_out, = plt.plot(percentages, knn_test, label=f'KNN Test Error (k={best_k})')\n",
    "\n",
    "    plt.title('Amount of Training Data vs. Decision Tree and KNN Error')\n",
    "    plt.xlabel('Amount of Training Data')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend(handles=[d_train_out, d_test_out, k_train_out, k_test_out])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running without scaling...\")\n",
    "    run_experiment(apply_scaling=False)\n",
    "\n",
    "    print(\"\\nRunning with scaling...\")\n",
    "    run_experiment(apply_scaling=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecMoiPhwqhtd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "18XBEwKgq8F5QdjQze_ObgwExe0V1d7Rk",
     "timestamp": 1673570527915
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
