{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch\n",
        "%pip install PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ57FP3Zdq19"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyqBmQZE7Uqw"
      },
      "outputs": [],
      "source": [
        "# # To add your own Drive Run this cell.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4RwWjtN2sf4"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# OneLayerNetwork\n",
        "######################################################################\n",
        "\n",
        "class OneLayerNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OneLayerNetwork, self).__init__()\n",
        "\n",
        "        ### ========== TODO : START ========== ###\n",
        "        ### part d: implement OneLayerNetwork with torch.nn.Linear\n",
        "        self.oneLayerNetwork = torch.nn.Linear(784,3)\n",
        "       \n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = (n_batch, n_features)\n",
        "\n",
        "        ### ========== TODO : START ========== ###\n",
        "        ### part d: implement the foward function\n",
        "        outputs = self.oneLayerNetwork(x)\n",
        "        ### ========== TODO : END ========== ###\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRbW6WPv25tE"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# TwoLayerNetwork\n",
        "######################################################################\n",
        "\n",
        "class TwoLayerNetwork(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoLayerNetwork, self).__init__()\n",
        "        ### ========== TODO : START ========== ###\n",
        "        ### part g: implement TwoLayerNetwork with torch.nn.Linear\n",
        "        self.twoLayerNetwork_1 = torch.nn.Linear(784, 400)\n",
        "        self.twoLayerNetwork_2 = torch.nn.Linear(400, 3)\n",
        "        ### ========== TODO : END ========== ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape = (n_batch, n_features)\n",
        "\n",
        "        ### ========== TODO : START ========== ###\n",
        "        ### part g: implement the foward function\n",
        "        sig = torch.nn.Sigmoid()\n",
        "        layer_1 = self.twoLayerNetwork_1(x)\n",
        "        layer_1 = sig(layer_1)\n",
        "        outputs = self.twoLayerNetwork_2(layer_1)\n",
        "        ### ========== TODO : END ========== ###\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I06zHwgTeSs3"
      },
      "outputs": [],
      "source": [
        "# load data from csv\n",
        "# X.shape = (n_examples, n_features), y.shape = (n_examples, )\n",
        "def load_data(filename):\n",
        "    data = np.loadtxt(filename)\n",
        "    y = data[:, 0].astype(int)\n",
        "    X = data[:, 1:].astype(np.float32) / 255\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvP1DJfteUOn"
      },
      "outputs": [],
      "source": [
        "# plot one example\n",
        "# x.shape = (features, )\n",
        "def plot_img(x):\n",
        "    x = x.reshape(28, 28)\n",
        "    img = Image.fromarray(x*255)\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqaCgw9Z4Eef"
      },
      "outputs": [],
      "source": [
        "def evaluate_loss(model, criterion, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEnwn4sC4F3B"
      },
      "outputs": [],
      "source": [
        "def evaluate_acc(model, dataloader):\n",
        "    model.eval()\n",
        "    total_acc = 0.0\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        outputs = model(batch_X)\n",
        "        predictions = torch.argmax(outputs, dim=1)\n",
        "        total_acc += (predictions==batch_y).sum()\n",
        "        \n",
        "    return total_acc / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OpXc_t7Jc5_"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, train_loader, valid_loader, epochs=31):\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    train_acc_list = []\n",
        "    valid_acc_list = []\n",
        "    for epoch in range(1, epochs):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            pass\n",
        "            ### ========== TODO : START ========== ###\n",
        "            ### part f: implement the training process\n",
        "            #forward pass\n",
        "            y_pred = model.forward(batch_X)\n",
        "            #initializing gradients to zeroes\n",
        "            model.zero_grad()\n",
        "            #computing loss\n",
        "            loss = criterion(y_pred, batch_y)\n",
        "            #loss backward\n",
        "            loss.backward()\n",
        "            #updating model parameters\n",
        "            optimizer.step()\n",
        "           \n",
        "            \n",
        "            ### ========== TODO : END ========== ###\n",
        "            \n",
        "        train_loss = evaluate_loss(model, criterion, train_loader)\n",
        "        valid_loss = evaluate_loss(model, criterion, valid_loader)\n",
        "        train_acc = evaluate_acc(model, train_loader)\n",
        "        valid_acc = evaluate_acc(model, valid_loader)\n",
        "        train_loss_list.append(train_loss)\n",
        "        valid_loss_list.append(valid_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        valid_acc_list.append(valid_acc)\n",
        "\n",
        "        print(f\"| epoch {epoch:2d} | train loss {train_loss:.6f} | train acc {train_acc:.6f} | valid loss {valid_loss:.6f} | valid acc {valid_acc:.6f} |\")\n",
        "\n",
        "    return train_loss_list, valid_loss_list, train_acc_list, valid_acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMmurb4-d39G"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# main\n",
        "######################################################################\n",
        "\n",
        "# def main():\n",
        "\n",
        "# fix random seed\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# load data with correct file path\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "data_directory_path =  \"./data/\"\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "# X.shape = (n_examples, n_features)\n",
        "# y.shape = (n_examples, )\n",
        "X_train, y_train = load_data(os.path.join(data_directory_path, \"ps3_train.csv\"))\n",
        "X_valid, y_valid = load_data(os.path.join(data_directory_path, \"ps3_valid.csv\"))\n",
        "X_test, y_test = load_data(os.path.join(data_directory_path, \"ps3_test.csv\"))\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part a: print out three training images with different labels\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(len(X_train), 3, replace=False)\n",
        "for idx in indices:\n",
        "    plot_img(X_train[idx])\n",
        "\n",
        "\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "print(\"Data preparation...\")\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part b: convert numpy arrays to tensors\n",
        "X_train = torch.from_numpy(X_train)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "\n",
        "X_valid = torch.from_numpy(X_valid)\n",
        "y_valid = torch.from_numpy(y_valid)\n",
        "\n",
        "X_test = torch.from_numpy(X_test)\n",
        "y_test = torch.from_numpy(y_test)\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part c: prepare dataloaders for training, validation, and testing\n",
        "###         we expect to get a batch of pairs (x_n, y_n) from the dataloader\n",
        "### train_loader = ...\n",
        "### valid_loader = ...\n",
        "### test_loader = ...\n",
        "train_loader = DataLoader(TensorDataset(X_train,y_train), batch_size=10)\n",
        "valid_loader = DataLoader(TensorDataset(X_valid,y_valid), batch_size=10)\n",
        "test_loader = DataLoader(TensorDataset(X_test,y_test), batch_size=10)\n",
        "\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part e: prepare OneLayerNetwork, criterion, and optimizer\n",
        "model_one = OneLayerNetwork()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_one.parameters(), lr=0.0005)\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "print(\"Start training OneLayerNetwork...\")\n",
        "results_one = train(model_one, criterion, optimizer, train_loader, valid_loader, epochs=31)\n",
        "print(\"Done!\")\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part h: prepare TwoLayerNetwork, criterion, and optimizer\n",
        "model_two = TwoLayerNetwork()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_two.parameters(), lr=0.0005)\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "print(\"Start training TwoLayerNetwork...\")\n",
        "results_two = train(model_two, criterion, optimizer, train_loader, valid_loader, epochs=31)\n",
        "print(\"Done!\")\n",
        "\n",
        "one_train_loss, one_valid_loss, one_train_acc, one_valid_acc = results_one\n",
        "two_train_loss, two_valid_loss, two_train_acc, two_valid_acc = results_two"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCYGcy_CoKQM"
      },
      "outputs": [],
      "source": [
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part i: generate a plot to comare one_train_loss, one_valid_loss, two_train_loss, two_valid_loss\n",
        "epochs = np.arange(1, 31)\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.plot(epochs, one_train_loss, color='red', label='1 layer train loss', marker='o')\n",
        "plt.plot(epochs, one_valid_loss, color='green', label='1 layer valid loss', marker='o')\n",
        "plt.plot(epochs, two_train_loss, color='blue', label='2 layer train loss', marker='o')\n",
        "plt.plot(epochs, two_valid_loss, color='lightblue', label='2 layer valid loss', marker='o')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('comare one layer and two layer train and valid loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part j: generate a plot to comare one_train_acc, one_valid_acc, two_train_acc, two_valid_acc\n",
        "epochs = np.arange(1, 31)\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.plot(epochs, one_train_acc, color='red', label='1 layer train accuracy', marker='o')\n",
        "plt.plot(epochs, one_valid_acc, color='green', label='1 layer valid accuracy', marker='o')\n",
        "plt.plot(epochs, two_train_acc, color='blue', label='2 layer train accuracy', marker='o')\n",
        "plt.plot(epochs, two_valid_acc, color='lightblue', label='2 layer valid accuracy', marker='o')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('comare one layer and two layer train and valid accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "### ========== TODO : END ========== ##\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part k: calculate the test accuracy\n",
        "print(\"test accuracy of one layer network: \", evaluate_acc(model_one, test_loader))\n",
        "print(\"test accuracy of two layer network: \", evaluate_acc(model_two, test_loader))\n",
        "\n",
        "\n",
        "\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "### ========== TODO : START ========== ###\n",
        "### part l: replace the SGD optimizer with the Adam optimizer and do the experiments again\n",
        "train_loader = DataLoader(TensorDataset(X_train,y_train), batch_size=10)\n",
        "valid_loader = DataLoader(TensorDataset(X_valid,y_valid), batch_size=10)\n",
        "test_loader = DataLoader(TensorDataset(X_test,y_test), batch_size=10)\n",
        "\n",
        "model_one = OneLayerNetwork()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_one.parameters(), lr=0.0005)\n",
        "\n",
        "print(\"Start training OneLayerNetwork...\")\n",
        "results_one = train(model_one, criterion, optimizer, train_loader, valid_loader)\n",
        "print(\"Done!\")\n",
        "\n",
        "model_two = TwoLayerNetwork()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_two.parameters(), lr=0.0005)\n",
        "\n",
        "print(\"Start training TwoLayerNetwork...\")\n",
        "results_two = train(model_two, criterion, optimizer, train_loader, valid_loader)\n",
        "print(\"Done!\")\n",
        "\n",
        "one_train_loss, one_valid_loss, one_train_acc, one_valid_acc = results_one\n",
        "two_train_loss, two_valid_loss, two_train_acc, two_valid_acc = results_two\n",
        "\n",
        "epochs = np.arange(1, 31)\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.plot(epochs, one_train_loss, color='red', label='1 layer train loss', marker='o')\n",
        "plt.plot(epochs, one_valid_loss, color='green', label='1 layer valid loss', marker='o')\n",
        "plt.plot(epochs, two_train_loss, color='blue', label='2 layer train loss', marker='o')\n",
        "plt.plot(epochs, two_valid_loss, color='lightblue', label='2 layer valid loss', marker='o')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('comare one layer and two layer train and valid loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "epochs = np.arange(1, 31)\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.plot(epochs, one_train_acc, color='red', label='1 layer train accuracy', marker='o')\n",
        "plt.plot(epochs, one_valid_acc, color='green', label='1 layer valid accuracy', marker='o')\n",
        "plt.plot(epochs, two_train_acc, color='blue', label='2 layer train accuracy', marker='o')\n",
        "plt.plot(epochs, two_valid_acc, color='lightblue', label='2 layer valid accuracy', marker='o')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('comare one layer and two layer train and valid accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"test accuracy of one layer network: \", evaluate_acc(model_one, test_loader))\n",
        "print(\"test accuracy of two layer network: \", evaluate_acc(model_two, test_loader))\n",
        "### ========== TODO : END ========== ###\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
