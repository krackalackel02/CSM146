{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcxSra45yOOo"
   },
   "outputs": [],
   "source": [
    "# This code was adapted from course material by Jenna Wiens (UMichigan).\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRdIx3RBylgK"
   },
   "outputs": [],
   "source": [
    "# Please specify the full paths to the regression_train.csv\n",
    "# and regression_test.csv files in your gdrive directory\n",
    "### ========== TODO : START ========== ###\n",
    "train_path = 'regression_train.csv'\n",
    "test_path = 'regression_test.csv'\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9rpA_5cyqNm"
   },
   "outputs": [],
   "source": [
    "# Use only the provided packages!\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLUu5cxX00O1"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# classes\n",
    "######################################################################\n",
    "\n",
    "class Data :\n",
    "\n",
    "    def __init__(self, X=None, y=None) :\n",
    "        \"\"\"\n",
    "        Data class. \n",
    "\n",
    "        Attributes\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,d), features\n",
    "            y       -- numpy array of shape (n,), targets\n",
    "        \"\"\"\n",
    "\n",
    "        # n = number of examples, d = dimensionality\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def load(self, filename) :\n",
    "        \"\"\"\n",
    "        Load csv file into X array of features and y array of labels.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            filename -- string, filename\n",
    "        \"\"\"\n",
    "\n",
    "        # load data\n",
    "        with open(filename, 'r') as fid :\n",
    "            data = np.loadtxt(fid, delimiter=\",\")\n",
    "\n",
    "        # separate features and labels\n",
    "        self.X = data[:,:-1]\n",
    "        self.y = data[:,-1]\n",
    "\n",
    "    def plot(self, **kwargs) :\n",
    "        \"\"\"Plot data.\"\"\"\n",
    "\n",
    "        if 'color' not in kwargs :\n",
    "            kwargs['color'] = 'b'\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.scatter(self.X, self.y, **kwargs)\n",
    "        plt.xlabel('x', fontsize = 16)\n",
    "        plt.ylabel('y', fontsize = 16)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HyK8xJC03x9"
   },
   "outputs": [],
   "source": [
    "# wrapper functions around Data class\n",
    "def load_data(filename) :\n",
    "    data = Data()\n",
    "    data.load(filename)\n",
    "    return data\n",
    "\n",
    "def plot_data(X, y, **kwargs) :\n",
    "    data = Data(X, y)\n",
    "    data.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocdVqDteL3sx"
   },
   "outputs": [],
   "source": [
    "def plot_erms(mrange, train_errs, test_errs):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(mrange, train_errs, 'o-', color='red', label='Training')\n",
    "    plt.plot(mrange, test_errs, 'o-', color='blue', label='Test')\n",
    "    plt.xlabel(r'$m$', fontsize = 16)\n",
    "    plt.ylabel(r'$E_{RMS}$', fontsize = 16)\n",
    "    plt.title('Polynomial regression error')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAqbE9ar08Rh"
   },
   "outputs": [],
   "source": [
    "class PolynomialRegression() :\n",
    "\n",
    "    def __init__(self, m=1) :\n",
    "        \"\"\"\n",
    "        Ordinary least squares regression.\n",
    "\n",
    "        Attributes\n",
    "        --------------------\n",
    "            coef_   -- numpy array of shape (d,)\n",
    "                       estimated coefficients for the linear regression problem\n",
    "            m_      -- integer\n",
    "                       order for polynomial regression\n",
    "        \"\"\"\n",
    "        self.coef_ = None\n",
    "        self.m_ = m\n",
    "\n",
    "\n",
    "    def generate_polynomial_features(self, X) :\n",
    "        \"\"\"\n",
    "        Maps X to an mth degree feature vector e.g. [1, X, X^2, ..., X^m].\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,1), features\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            Phi     -- numpy array of shape (n,(m+1)), mapped features\n",
    "        \"\"\"\n",
    "\n",
    "        n,d = X.shape\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part b: modify to create matrix for simple linear model\n",
    "        # part g: modify to create matrix for polynomial model\n",
    "        m = self.m_\n",
    "        Phi = np.ones([n,1])\n",
    "        for i in range(1, m + 1):\n",
    "          Phi = np.append(Phi, X ** i, 1)\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "        return Phi\n",
    "\n",
    "\n",
    "    def fit_GD(self, X, y, eta=None,\n",
    "                eps=0, tmax=10000, verbose=False) :\n",
    "        \"\"\"\n",
    "        Finds the coefficients of a {d-1}^th degree polynomial\n",
    "        that fits the data using least squares batch gradient descent.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,d), features\n",
    "            y       -- numpy array of shape (n,), targets\n",
    "            eta     -- float, step size\n",
    "            eps     -- float, convergence criterion\n",
    "            tmax    -- integer, maximum number of iterations\n",
    "            verbose -- boolean, for debugging purposes\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            self    -- an instance of self\n",
    "        \"\"\"\n",
    "\n",
    "        if verbose :\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.xlabel('iteration')\n",
    "            plt.ylabel(r'$J(\\theta)$')\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "\n",
    "        X = self.generate_polynomial_features(X) # map features\n",
    "        n,d = X.shape\n",
    "        eta_input = eta\n",
    "        self.coef_ = np.zeros(d)                 # coefficients\n",
    "        err_list  = np.zeros((tmax,1))           # errors per iteration\n",
    "        start  = time.time()        \n",
    "\n",
    "        # GD loop\n",
    "        for t in range(tmax) :\n",
    "            ### ========== TODO : START ========== ###\n",
    "            # part f: update step size\n",
    "            # change the default eta in the function signature to 'eta=None'\n",
    "            # and update the line below to your learning rate function\n",
    "            if eta_input is None :\n",
    "                eta = 1/(1+t) # change this line\n",
    "            else :\n",
    "                eta = eta_input\n",
    "            ### ========== TODO : END ========== ###\n",
    "\n",
    "            ### ========== TODO : START ========== ###\n",
    "            # part d: update theta (self.coef_) using one step of GD\n",
    "            # hint: you can write simultaneously update all theta using vector math\n",
    "            weights = np.array(list(self.coef_))\n",
    "            for i ,val in enumerate(weights):\n",
    "                total = 0\n",
    "                for j,x in enumerate(X):\n",
    "                    total += (np.dot(weights.T,x) - y[j])*x[i]\n",
    "                self.coef_[i] = val - 2*eta*total\n",
    "\n",
    "\n",
    "            # track error\n",
    "            # hint: you cannot use self.predict(...) to make the predictions\n",
    "            y_pred = np.dot(X,np.transpose(self.coef_)) # change this line\n",
    "            err_list[t] = np.sum(np.power(y - y_pred, 2)) / float(n)\n",
    "            ### ========== TODO : END ========== ###\n",
    "\n",
    "            # stop?\n",
    "            if t > 0 and abs(err_list[t] - err_list[t-1]) <= eps :\n",
    "                break\n",
    "\n",
    "            # debugging\n",
    "            if verbose :\n",
    "                x = np.reshape(X[:,1], (n,1))\n",
    "                cost = self.cost(x,y)\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.cla()\n",
    "                plot_data(x, y)\n",
    "                self.plot_regression()\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot([t+1], [cost], 'bo')\n",
    "                plt.suptitle('iteration: %d, cost: %f' % (t+1, cost))\n",
    "                plt.draw()\n",
    "                plt.pause(0.05) # pause for 0.05 sec\n",
    "\n",
    "        print('GD Coeff')\n",
    "        print(self.coef_)\n",
    "        finish = time.time()        \n",
    "        print('Time to compute closed form solution: %f seconds' % (finish-start))      \n",
    "        print('number of iterations: %d' % (t+1))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fit(self, X, y) :\n",
    "        \"\"\"\n",
    "        Finds the coefficients of a {d-1}^th degree polynomial\n",
    "        that fits the data using the closed form solution.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,d), features\n",
    "            y       -- numpy array of shape (n,), targets\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            self    -- an instance of self\n",
    "        \"\"\"\n",
    "\n",
    "        X = self.generate_polynomial_features(X) # map features\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part e: implement closed-form solution\n",
    "        # hint: use np.dot(...) and np.linalg.pinv(...)\n",
    "        #       be sure to update self.coef_ with your solution\n",
    "        start  = time.time()\n",
    "        self.coef_ = np.dot(np.dot(np.linalg.pinv(np.dot(np.transpose(X),X)),np.transpose(X)),y)\n",
    "        finish = time.time()\n",
    "        print('Time to compute closed form solution: %f seconds' % (finish-start))\n",
    "        print('Closed Form Coeff')\n",
    "        print(self.coef_)\n",
    "        \n",
    "\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "    def predict(self, X) :\n",
    "        \"\"\"\n",
    "        Predict output for X.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,d), features\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            y       -- numpy array of shape (n,), predictions\n",
    "        \"\"\"\n",
    "        if self.coef_ is None :\n",
    "            raise Exception(\"Model not initialized. Perform a fit first.\")\n",
    "\n",
    "        X = self.generate_polynomial_features(X) # map features\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part c: predict y\n",
    "        y = np.dot(X,np.transpose(self.coef_))\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "    def cost(self, X, y) :\n",
    "        \"\"\"\n",
    "        Calculates the objective function.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,d), features\n",
    "            y       -- numpy array of shape (n,), targets\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            cost    -- float, objective J(theta)\n",
    "        \"\"\"\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part d: compute J(theta)\n",
    "        cost = 0\n",
    "        h = self.predict(X)\n",
    "        for i in range(len(y)):\n",
    "            cost += (h[i] - y[i])**2\n",
    "        ### ========== TODO : END ========== ###\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def rms_error(self, X, y) :\n",
    "        \"\"\"\n",
    "        Calculates the root mean square error.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X       -- numpy array of shape (n,d), features\n",
    "            y       -- numpy array of shape (n,), targets\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            error   -- float, RMSE\n",
    "        \"\"\"\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part h: compute RMSE\n",
    "        error = np.sqrt(self.cost(X, y)/len(X))\n",
    "        ### ========== TODO : END ========== ###\n",
    "        return error\n",
    "\n",
    "\n",
    "    def plot_regression(self, xmin=0, xmax=1, n=50, **kwargs) :\n",
    "        \"\"\"Plot regression line.\"\"\"\n",
    "        if 'color' not in kwargs :\n",
    "            kwargs['color'] = 'r'\n",
    "        if 'linestyle' not in kwargs :\n",
    "            kwargs['linestyle'] = '-'\n",
    "\n",
    "        X = np.reshape(np.linspace(0,1,n), (n,1))\n",
    "        y = self.predict(X)\n",
    "        plot_data(X, y, **kwargs)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1vG8LDm1FKW"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# main\n",
    "######################################################################\n",
    "\n",
    "def main():\n",
    "    # load data\n",
    "    train_data = load_data(train_path)\n",
    "    test_data = load_data(test_path)\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part a: main code for visualizations\n",
    "    print('Visualizing data...')\n",
    "    plot_data(train_data.X, train_data.y,color='blue')\n",
    "    plot_data(test_data.X, test_data.y,color='red')\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # parts b-f: main code for linear regression\n",
    "    print('Investigating linear regression...')\n",
    "    model = PolynomialRegression(1)\n",
    "    model.coef_ = np.zeros(2)\n",
    "    print('Part D 1')\n",
    "    print('Expected Cost of approx 40.234')\n",
    "    print(model.cost(train_data.X, train_data.y))\n",
    "    print('Part D 3')\n",
    "    rates = [1e-6, 1e-5, 1e-3, 0.1]\n",
    "    for eta in rates:\n",
    "        model.fit_GD(train_data.X, train_data.y, eta=eta)\n",
    "        print('Cost for eta = ', eta)\n",
    "        print(model.cost(train_data.X, train_data.y))\n",
    "    print('Part E')\n",
    "    model.fit(train_data.X, train_data.y)\n",
    "    print('Part F')\n",
    "    model.fit_GD(train_data.X, train_data.y, eta=None)\n",
    "    print(model.cost(train_data.X, train_data.y))\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # parts g-i: main code for polynomial regression\n",
    "    print(\"Investigating polynomial regression...\")\n",
    "    trn_error = []\n",
    "    tst_error = []\n",
    "    X_train = train_data.X\n",
    "    y_train = train_data.y\n",
    "    X_test = test_data.X\n",
    "    y_test = test_data.y\n",
    "    order = np.arange(11)\n",
    "    for deg in range(11):\n",
    "      model = PolynomialRegression(deg)\n",
    "      model.fit(X_train, y_train)\n",
    "      trn_error.append(model.rms_error(X_train, y_train))\n",
    "      tst_error.append(model.rms_error(X_test, y_test))\n",
    "    \n",
    "    plt.plot(order, trn_error, color = \"blue\", label=\"Training Error\")\n",
    "    plt.plot(order, tst_error, color = \"red\", label=\"Testing Error\")\n",
    "    plt.xlabel(\"Polynomial Order\")\n",
    "    plt.ylabel(\"Error (RMSE)\")\n",
    "    plt.title(\"Polynomial Order vs. Error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-v2OAMyCcyko"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
